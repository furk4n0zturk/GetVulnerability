import requests
import urllib3
from bs4 import BeautifulSoup
from lxml import etree
import openpyxl
import os
import argparse
from datetime import datetime

class cwe:
    def __init__(self):
        list = open("cwelist")
        fileContent = list.read()
        self.cwelist = fileContent.splitlines()

        def valid_date(date_string):
            try:
                formatted_date = datetime.strptime(date_string, "%m.%d.%Y")
                return formatted_date.strftime("%m.%d.%Y")
            except ValueError:
                msg = f"Invalid Date Format: '{date_string}'. Valid Foramt: 'MM.DD.YYYY'"
                raise argparse.ArgumentTypeError(msg)

        parser = argparse.ArgumentParser()
        parser.add_argument("--start_date", "-s", help="MM.DD.YYYY\n",type=valid_date)
        parser.add_argument("--end_date", "-e", help="MM.DD.YYYY\n",type=valid_date)
        self.args = parser.parse_args()
        self.converted_start_date = self.args.start_date.replace('.', '%2F')
        self.converted_end_date = self.args.end_date.replace('.', '%2F')

        self.getCWE()
        self.getMostCWE()

    def getCWE(self):
        for self.cwe in self.cwelist:

            url = "https://nvd.nist.gov/vuln/search/results?isCpeNameSearch=false&cvss_version=3&pub_start_date={}&cwe_id={}&pub_end_date={}&results_type=overview&form_type=Advanced&search_type=all&startIndex=".format(self.converted_start_date, self.cwe, self.converted_end_date)
            req = requests.get(url)
            soup = BeautifulSoup(req.content, "html.parser")
            source = str(soup)

            if '<strong data-testid="vuln-matching-records-count">0</strong>' not in source:
                dom = etree.HTML(str(soup))
                self.name = dom.xpath(f'//*[@id="search-params-panel"]/ul/li[3]/span[3]')[0].text
                self.total = dom.xpath(f'/html/body/main/div/div/div[2]/div/div[1]/div[2]/strong')[0].text

                cr_url = "https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cwe_id={}&isCpeNameSearch=false&cvss_version=3&cvss_v3_severity=CRITICAL&pub_start_date={}&pub_end_date={}".format(self.cwe, self.converted_start_date, self.converted_end_date)
                req = requests.get(cr_url)
                soup = BeautifulSoup(req.content, "html.parser")
                dom = etree.HTML(str(soup))
                self.critical = dom.xpath(f'/html/body/main/div/div/div[2]/div/div[1]/div[2]/strong')[0].text

                hi_url = "https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cwe_id={}&isCpeNameSearch=false&cvss_version=3&cvss_v3_severity=HIGH&pub_start_date={}&pub_end_date={}".format(self.cwe, self.converted_start_date, self.converted_end_date)
                req = requests.get(hi_url)
                soup = BeautifulSoup(req.content, "html.parser")
                dom = etree.HTML(str(soup))
                self.high = dom.xpath(f'/html/body/main/div/div/div[2]/div/div[1]/div[2]/strong')[0].text

                med_url = "https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cwe_id={}&isCpeNameSearch=false&cvss_version=3&cvss_v3_severity=MEDIUM&pub_start_date={}&pub_end_date={}".format(self.cwe, self.converted_start_date, self.converted_end_date)
                req = requests.get(med_url)
                soup = BeautifulSoup(req.content, "html.parser")
                dom = etree.HTML(str(soup))
                self.medium = dom.xpath(f'/html/body/main/div/div/div[2]/div/div[1]/div[2]/strong')[0].text

                low_url = "https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cwe_id={}&isCpeNameSearch=false&cvss_version=3&cvss_v3_severity=LOW&pub_start_date={}&pub_end_date={}".format(self.cwe, self.converted_start_date, self.converted_end_date)
                req = requests.get(low_url)
                soup = BeautifulSoup(req.content, "html.parser")
                dom = etree.HTML(str(soup))
                self.low = dom.xpath(f'/html/body/main/div/div/div[2]/div/div[1]/div[2]/strong')[0].text
                self.getCWEDetails()
                self.vulnStats()

    def getCWEDetails(self):

        workbook = openpyxl.load_workbook("vulnerability_report.xlsx") if "vulnerability_report.xlsx" in os.listdir() else openpyxl.Workbook()
        sheet = workbook.active
        sheet.title = "CWE List"

        sheet["A1"] = "CWE Name"
        sheet["B1"] = "Total"
        sheet["C1"] = "Critical"
        sheet["D1"] = "High"
        sheet["E1"] = "Medium"
        sheet["F1"] = "Low"

        next_row = sheet.max_row + 1
        sheet[f"A{next_row}"] = self.name
        sheet[f"B{next_row}"] = self.total
        sheet[f"C{next_row}"] = self.critical
        sheet[f"D{next_row}"] = self.high
        sheet[f"E{next_row}"] = self.medium
        sheet[f"F{next_row}"] = self.low

        workbook.save("vulnerability_report.xlsx")
        workbook.close()

    def getMostCWE(self):
        workbook = openpyxl.load_workbook("vulnerability_report.xlsx")
        data_sheet = workbook["CWE List"]

        data = []
        for row in data_sheet.iter_rows(min_row=2, values_only=True):
            data.append(row)

        sorted_data = sorted(data, key=lambda x: int(x[1]), reverse=True)

        top_5_cwes = sorted_data[:5]

        if "Most CWE's" in workbook.sheetnames:
            most_cwes_sheet = workbook["Most CWE's"]
        else:
            most_cwes_sheet = workbook.create_sheet("Most CWE's")

        most_cwes_sheet["A1"] = "CWE Name"
        most_cwes_sheet["B1"] = "Total"
        most_cwes_sheet["C1"] = "Critical"
        most_cwes_sheet["D1"] = "High"
        most_cwes_sheet["E1"] = "Medium"
        most_cwes_sheet["F1"] = "Low"

        for index, cwe_data in enumerate(top_5_cwes, start=2):
            most_cwes_sheet[f"A{index}"] = cwe_data[0]
            most_cwes_sheet[f"B{index}"] = cwe_data[1]
            most_cwes_sheet[f"C{index}"] = cwe_data[2]
            most_cwes_sheet[f"D{index}"] = cwe_data[3]
            most_cwes_sheet[f"E{index}"] = cwe_data[4]
            most_cwes_sheet[f"F{index}"] = cwe_data[5]

        workbook.save("vulnerability_report.xlsx")
        workbook.close()
    def vulnStats(self):
        workbook = openpyxl.load_workbook("vulnerability_report.xlsx")
        data_sheet = workbook["CWE List"]

        data = []
        for row in data_sheet.iter_rows(min_row=2, values_only=True):
            data.append(row)

        total_sum = sum(int(row[1]) for row in data)
        critical_sum = sum(int(row[2]) for row in data)
        high_sum = sum(int(row[3]) for row in data)
        medium_sum = sum(int(row[4]) for row in data)
        low_sum = sum(int(row[5]) for row in data)

        if "Vuln Stats" in workbook.sheetnames:
            vuln_stats_sheet = workbook["Vuln Stats"]
        else:
            vuln_stats_sheet = workbook.create_sheet("Vuln Stats")

        vuln_stats_sheet["A1"] = "Total"
        vuln_stats_sheet["B1"] = total_sum

        vuln_stats_sheet["A2"] = "Critical"
        vuln_stats_sheet["B2"] = critical_sum

        vuln_stats_sheet["A3"] = "High"
        vuln_stats_sheet["B3"] = high_sum

        vuln_stats_sheet["A4"] = "Medium"
        vuln_stats_sheet["B4"] = medium_sum

        vuln_stats_sheet["A5"] = "Low"
        vuln_stats_sheet["B5"] = low_sum

        workbook.save("vulnerability_report.xlsx")
        workbook.close()

cwe()



        
